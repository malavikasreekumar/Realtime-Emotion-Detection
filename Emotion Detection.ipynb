{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading file\n",
    "df=pd.read_csv(r'S:\\ML Projects\\Facial Expression\\fer2013\\fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method IndexOpsMixin.value_counts of 0           Training\n",
      "1           Training\n",
      "2           Training\n",
      "3           Training\n",
      "4           Training\n",
      "5           Training\n",
      "6           Training\n",
      "7           Training\n",
      "8           Training\n",
      "9           Training\n",
      "10          Training\n",
      "11          Training\n",
      "12          Training\n",
      "13          Training\n",
      "14          Training\n",
      "15          Training\n",
      "16          Training\n",
      "17          Training\n",
      "18          Training\n",
      "19          Training\n",
      "20          Training\n",
      "21          Training\n",
      "22          Training\n",
      "23          Training\n",
      "24          Training\n",
      "25          Training\n",
      "26          Training\n",
      "27          Training\n",
      "28          Training\n",
      "29          Training\n",
      "            ...     \n",
      "35857    PrivateTest\n",
      "35858    PrivateTest\n",
      "35859    PrivateTest\n",
      "35860    PrivateTest\n",
      "35861    PrivateTest\n",
      "35862    PrivateTest\n",
      "35863    PrivateTest\n",
      "35864    PrivateTest\n",
      "35865    PrivateTest\n",
      "35866    PrivateTest\n",
      "35867    PrivateTest\n",
      "35868    PrivateTest\n",
      "35869    PrivateTest\n",
      "35870    PrivateTest\n",
      "35871    PrivateTest\n",
      "35872    PrivateTest\n",
      "35873    PrivateTest\n",
      "35874    PrivateTest\n",
      "35875    PrivateTest\n",
      "35876    PrivateTest\n",
      "35877    PrivateTest\n",
      "35878    PrivateTest\n",
      "35879    PrivateTest\n",
      "35880    PrivateTest\n",
      "35881    PrivateTest\n",
      "35882    PrivateTest\n",
      "35883    PrivateTest\n",
      "35884    PrivateTest\n",
      "35885    PrivateTest\n",
      "35886    PrivateTest\n",
      "Name: Usage, Length: 35887, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Usage\"].value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining variables\n",
    "X_train,y_train,X_test,y_test=[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           y_train.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           y_test.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample data:[array([ 70.,  80.,  82., ..., 106., 109.,  82.], dtype=float32), array([151., 150., 147., ..., 193., 183., 184.], dtype=float32)]\n",
      "y_train sample data:[0, 0]\n",
      "X_test sample data:[array([254., 254., 254., ...,  42., 129., 180.], dtype=float32), array([156., 184., 198., ..., 172., 167., 161.], dtype=float32)]\n",
      "y_test sample data:[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train sample data:{X_train[0:2]}\")\n",
    "print(f\"y_train sample data:{y_train[0:2]}\")\n",
    "print(f\"X_test sample data:{X_test[0:2]}\")\n",
    "print(f\"y_test sample data:{y_test[0:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train,'float32')\n",
    "y_train=np.array(y_train,'float32')\n",
    "X_test=np.array(X_test,'float32')\n",
    "y_test=np.array(y_test,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the dataset between 0 and 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the dataset so that keras accept it.\n",
    "num_features=64\n",
    "num_labels=7\n",
    "batch_size=64\n",
    "epochs=30\n",
    "width,height=48,48\n",
    "\n",
    "X_train=X_train.reshape(X_train.shape[0],width,height,1)\n",
    "X_test=X_test.reshape(X_test.shape[0],width,height,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designing CNN in keras\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization,Dense\n",
    "#model = tensorflow.keras.Sequential()\n",
    "model=Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st convolutional layer\n",
    "model.add(Conv2D(num_features,kernel_size=(3,3),activation='relu',input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(num_features,kernel_size=(3,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking maxium value from pool and using it as output\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "#Dropout so model does not overfit \n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_resnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f20b40072e07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_resnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_resnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_resnet'"
     ]
    }
   ],
   "source": [
    "import keras_resnet\n",
    "import keras_resnet.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd convolutional layer\n",
    "model.add(Conv2D(num_features,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(num_features,kernel_size=(3,3),activation='relu'))\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    " \n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/30\n",
      "15424/28709 [===============>..............] - ETA: 9:27 - loss: 2268577386.7095 - accuracy: 0.0017"
     ]
    }
   ],
   "source": [
    "#3rd convolutional layer\n",
    "model.add(Conv2D(2*num_features,(3,3),activation='relu'))\n",
    "model.add(Conv2D(2*num_features,(3,3),activation='relu'))\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#Adding Dense layers\n",
    "model.add(Dense(2*2*num_features,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2*2*num_features,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels,activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,optimizers=Adam(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "        verbose=1,\n",
    "         validation_data=(X_test,y_test),\n",
    "         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
